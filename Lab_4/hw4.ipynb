{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hw4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4f3e01a70ef644018b6a27d290a0d2a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5cce9adefba9405081331a4eaa478b5c",
              "IPY_MODEL_cd8ad93feab24611a25e97277af9f9c9",
              "IPY_MODEL_b96e11cec7624e0196ad3160f13b5276"
            ],
            "layout": "IPY_MODEL_8345cfddd76a4bce9a0f9638b97fc394"
          }
        },
        "5cce9adefba9405081331a4eaa478b5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a80d199fc2a4ee39fa970209163d041",
            "placeholder": "​",
            "style": "IPY_MODEL_875090ec2126429b844b6857a2e73828",
            "value": "100%"
          }
        },
        "cd8ad93feab24611a25e97277af9f9c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd97c6fe54d14a909d47abc292aefb31",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df288c21b679402d84a5be8f967431e6",
            "value": 2
          }
        },
        "b96e11cec7624e0196ad3160f13b5276": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b9b89285604acc90924122ad1213c0",
            "placeholder": "​",
            "style": "IPY_MODEL_1b2d85e8d16d41d796994dc345fddfcb",
            "value": " 2/2 [00:00&lt;00:00, 37.98it/s]"
          }
        },
        "8345cfddd76a4bce9a0f9638b97fc394": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a80d199fc2a4ee39fa970209163d041": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "875090ec2126429b844b6857a2e73828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bd97c6fe54d14a909d47abc292aefb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df288c21b679402d84a5be8f967431e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c3b9b89285604acc90924122ad1213c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2d85e8d16d41d796994dc345fddfcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Soft deadline: `30.03.2022 23:59`"
      ],
      "metadata": {
        "id": "nXpkXz1QJmhJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxy7euTpCbGp"
      },
      "source": [
        "In this homework you will understand the fine-tuning procedure and get acquainted with Huggingface Datasets library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1MXcMymXeCx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02fbe96a-2b47-49c7-c05b-685aa4dc3ac6"
      },
      "source": [
        "! pip install datasets\n",
        "! pip install transformers\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.4)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.63.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.3)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.7.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.17.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FykUK-TFXf-2"
      },
      "source": [
        "For our goals we will use [Datasets](https://huggingface.co/docs/datasets/) library and take `yahoo_answers_topics` dataset - the task of this dataset is to divide documents on 10 topic categories. More detiled information can be found on the dataset [page](https://huggingface.co/datasets/viewer/).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ebsFAQsgXNB0"
      },
      "source": [
        "from datasets import load_dataset"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbzxZi42XOUG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "4f3e01a70ef644018b6a27d290a0d2a5",
            "5cce9adefba9405081331a4eaa478b5c",
            "cd8ad93feab24611a25e97277af9f9c9",
            "b96e11cec7624e0196ad3160f13b5276",
            "8345cfddd76a4bce9a0f9638b97fc394",
            "7a80d199fc2a4ee39fa970209163d041",
            "875090ec2126429b844b6857a2e73828",
            "bd97c6fe54d14a909d47abc292aefb31",
            "df288c21b679402d84a5be8f967431e6",
            "c3b9b89285604acc90924122ad1213c0",
            "1b2d85e8d16d41d796994dc345fddfcb"
          ]
        },
        "outputId": "ed06a23e-c8f1-482e-f038-67d4617eda79"
      },
      "source": [
        "dataset = load_dataset('yahoo_answers_topics') # the result is a dataset dictionary of train and test splits in this case"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset yahoo_answers_topics (/root/.cache/huggingface/datasets/yahoo_answers_topics/yahoo_answers_topics/1.0.0/b2712a72fde278f1d6e96cc4f485fd89ed2f79ecb231441e13645b53da021902)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f3e01a70ef644018b6a27d290a0d2a5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4U4YUOB5W8uG"
      },
      "source": [
        "# Fine-tuning the model** (20 points)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDYIq9l7CYBR"
      },
      "source": [
        "from transformers import (ElectraTokenizer, ElectraForSequenceClassification,\n",
        "                          get_scheduler, pipeline, ElectraForMaskedLM, ElectraModel, Trainer,TrainingArguments, InputFeatures)\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from datasets import load_metric\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElZ6k36rb0VG"
      },
      "source": [
        "Fine-tuning procedure on the end task consists of adding additional layers on the top of the pre-trained model. The resulting model can be tuned fully (passing gradients through the all model) or partially."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNEmksaPb3Uu"
      },
      "source": [
        "**Task**: \n",
        "- load tokenizer and model\n",
        "- look at the predictions of the model as-is before any fine-tuning\n",
        "\n",
        "\n",
        "```\n",
        "- Why don't you ask [MASK]?\n",
        "- What is [MASK]\n",
        "- Let's talk about [MASK] physics\n",
        "```\n",
        "\n",
        "- convert `best_answer` to the input tokens (supporting function for dataset is provided below) \n",
        "\n",
        "```\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"best_answer\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "```\n",
        "\n",
        "- define optimizer, sheduler (optional)\n",
        "- fine-tune the model (write the training loop), plot the loss changes and measure results in terms of weighted F1 score\n",
        "- get the masked word prediction (sample sentences above) on the fine-tuned model, why the results as they are and what should be done in order to change that (write down your answer)\n",
        "- Tune the training hyperparameters (and write down your results).\n",
        "\n",
        "**Tips**:\n",
        "- The easiest way to get predictions is to use transformers `pipeline` function \n",
        "- Do not forget to set `num_labels` parameter, when initializing the model\n",
        "- To convert data to batches use `DataLoader`\n",
        "- Even the `small` version of Electra can be long to train, so you can take data sample (>= 5000 and set seed for reproducibility)\n",
        "- You may want to try freezing (do not update the pretrained model weights) all the layers exept the ones for classification, in that case use:\n",
        "\n",
        "\n",
        "```\n",
        "for param in model.electra.parameters():\n",
        "      param.requires_grad = False\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yqAAFqZcwbu"
      },
      "source": [
        "MODEL_NAME = \"google/electra-small-generator\"\n",
        "TOKENIZER_NAME = \"google/electra-small-generator\""
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = ElectraTokenizer.from_pretrained(TOKENIZER_NAME)\n",
        "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=10)"
      ],
      "metadata": {
        "id": "MfXlkO9enhat",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21033b38-e65a-46b5-e39a-c213456cb6bf"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/783baabf823412158ef5569d9f79d40622cbebe10f9368a923f009a05f7c27df.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6509888bf1c7dd0be24a79d56757f6477c89b682006d884a767caf918033bef5.19eda9a6da5fb0e52a45200c95876729561dde16a69b9116953af6edca1d1e92\n",
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-small-generator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/electra-small-generator/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3198f768e07f18c7e8c6bedf8bae83eb6976a0cd29fd947f7c2eea1d03c19c74.70eb7a9661dc955e309afdd412fe4cf2a38225870027e600a01012bd47d92db4\n",
            "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.dense.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight', 'generator_predictions.dense.bias', 'generator_lm_head.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictor = pipeline(\"fill-mask\", model=MODEL_NAME)"
      ],
      "metadata": {
        "id": "ldJa_68bq-93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "263e83ef-6425-4436-fb3a-ddfc5b7ba743"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-small-generator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-small-generator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/electra-small-generator/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3198f768e07f18c7e8c6bedf8bae83eb6976a0cd29fd947f7c2eea1d03c19c74.70eb7a9661dc955e309afdd412fe4cf2a38225870027e600a01012bd47d92db4\n",
            "All model checkpoint weights were used when initializing ElectraForMaskedLM.\n",
            "\n",
            "All the weights of ElectraForMaskedLM were initialized from the model checkpoint at google/electra-small-generator.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForMaskedLM for predictions without further training.\n",
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-small-generator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/783baabf823412158ef5569d9f79d40622cbebe10f9368a923f009a05f7c27df.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/deffb00b3bf6ab6087ac52ffaadc5b49051cc22d364c65dbd5f0222f3c4e2ff6.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/google/electra-small-generator/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/6509888bf1c7dd0be24a79d56757f6477c89b682006d884a767caf918033bef5.19eda9a6da5fb0e52a45200c95876729561dde16a69b9116953af6edca1d1e92\n",
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"google/electra-small-generator\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predictions for 'Why don't you ask [MASK]?'\")\n",
        "print(f\"MASK can be: {[item['token_str'] for item in predictor('Why don`t you ask [MASK]?')]}\")\n",
        "print(\"======================================\")\n",
        "print(\"Predictions for 'What is [MASK]'\")\n",
        "print(f\"MASK can be: {[item['token_str'] for item in predictor('What is [MASK]')]}\")\n",
        "print(\"======================================\")\n",
        "print(\"Predictions for 'Let's talk about [MASK] physics'\")\n",
        "print(f\"MASK can be: {[item['token_str'] for item in predictor('Let`s talk about [MASK] physics')]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRlsLztxrD1q",
        "outputId": "392ec448-ef30-43a6-90d4-31cce9b6199c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for 'Why don't you ask [MASK]?'\n",
            "MASK can be: ['me', 'why', 'questions', 'them', 'yourself']\n",
            "======================================\n",
            "Predictions for 'What is [MASK]'\n",
            "MASK can be: ['?', '.', '!', '-', '\"']\n",
            "======================================\n",
            "Predictions for 'Let's talk about [MASK] physics'\n",
            "MASK can be: ['quantum', 'theoretical', 'particle', 'nuclear', 'real']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_ROWS = 5000"
      ],
      "metadata": {
        "id": "OIwPfawrOkDR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(data, num_rows):\n",
        "    return tokenizer(data[\"best_answer\"][:num_rows], padding=\"max_length\", truncation=True)"
      ],
      "metadata": {
        "id": "s5Fm-S_ksGpe"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train = tokenize_function(dataset[\"train\"], NUM_ROWS)\n",
        "tokenized_test = tokenize_function(dataset[\"test\"], NUM_ROWS)\n",
        "topics_train = dataset[\"train\"][\"topic\"][:NUM_ROWS]\n",
        "topics_test = dataset[\"test\"][\"topic\"][:NUM_ROWS]"
      ],
      "metadata": {
        "id": "YWcrdb4jsLeb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataSetImp(Dataset):\n",
        "    def __init__(self, tokenized_data,topics,length):\n",
        "      self.tokenized_data=tokenized_data\n",
        "      self.labels=topics\n",
        "      self.length=length\n",
        "\n",
        "    def __len__(self):\n",
        "      return (self.length)\n",
        "\n",
        "    def __getitem__(self, id):\n",
        "      return InputFeatures(\n",
        "            input_ids=self.tokenized_data['input_ids'][id],\n",
        "            token_type_ids=self.tokenized_data['token_type_ids'][id],\n",
        "            attention_mask=self.tokenized_data['attention_mask'][id],\n",
        "            label=self.labels[id])\n"
      ],
      "metadata": {
        "id": "1mwUMINDxtjJ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training = DataSetImp(tokenized_train, topics_train, NUM_ROWS)\n",
        "test = DataSetImp(tokenized_test, topics_test, NUM_ROWS)"
      ],
      "metadata": {
        "id": "WEnH4m83y7pd"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(7)\n",
        "torch.manual_seed(7)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/NLP/hw4/output\",\n",
        "    overwrite_output_dir=True,\n",
        "    evaluation_strategy=\"steps\",\n",
        "    num_train_epochs=5,\n",
        "    do_train=True,\n",
        "    do_eval=True)"
      ],
      "metadata": {
        "id": "g-BFqoJSzWar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe8640d-cbbb-45b0-8327-7937be8ec64e"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "using `logging_steps` to initialize `eval_steps` to 500\n",
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric('f1')\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    predictions, label_ids = pred\n",
        "    preds = np.argmax(predictions, axis=1)\n",
        "    return metric.compute(\n",
        "        predictions=preds, references=label_ids, average=\"weighted\")"
      ],
      "metadata": {
        "id": "kbPCE-FNzZ-L"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=training,\n",
        "    eval_dataset=test,\n",
        "    compute_metrics=compute_metrics\n",
        "    )"
      ],
      "metadata": {
        "id": "Bpclzw05znlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_result = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aWT2NPbszrtI",
        "outputId": "e0f5f9db-9974-4000-bc69-d9e1aaa0d610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 5000\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 8\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3125\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3125' max='3125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3125/3125 27:20, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>1.826200</td>\n",
              "      <td>1.556959</td>\n",
              "      <td>0.452080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>1.323100</td>\n",
              "      <td>1.398778</td>\n",
              "      <td>0.539183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>1.162800</td>\n",
              "      <td>1.379312</td>\n",
              "      <td>0.550924</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>1.011600</td>\n",
              "      <td>1.437068</td>\n",
              "      <td>0.546228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>1.458389</td>\n",
              "      <td>0.544384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.770600</td>\n",
              "      <td>1.459448</td>\n",
              "      <td>0.554506</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/hw4/output/checkpoint-500\n",
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/hw4/output/checkpoint-1000\n",
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-1000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-1000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/hw4/output/checkpoint-1500\n",
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-1500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-1500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/hw4/output/checkpoint-2000\n",
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-2000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-2000/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/hw4/output/checkpoint-2500\n",
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-2500/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-2500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n",
            "Saving model checkpoint to /content/drive/MyDrive/NLP/hw4/output/checkpoint-3000\n",
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-3000/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/output/checkpoint-3000/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_result"
      ],
      "metadata": {
        "id": "945v3fH7zzKk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adb36f63-cb91-4628-ef66-576edac3f8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=3125, training_loss=1.1476919702148438, metrics={'train_runtime': 1640.8097, 'train_samples_per_second': 15.236, 'train_steps_per_second': 1.905, 'total_flos': 735648921600000.0, 'train_loss': 1.1476919702148438, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [500, 1000,1500, 2000, 2500, 3000]\n",
        "loss = [1.826200, 1.323100, 1.162800, 1.011600, 0.883000, 0.770600]\n",
        "plt.plot(steps, loss)\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "7aWQULSnWh-8",
        "outputId": "9db41fd8-9106-444e-d280-383b0797395c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "steps = [500, 1000, 1500, 2000, 2500, 3000]\n",
        "loss = [1.556959, 1.398778, 1.379312, 1.437068, 1.458389, 1.459448]\n",
        "plt.plot(steps, loss)\n",
        "plt.xlabel(\"Step\")\n",
        "plt.ylabel(\"Validation Loss\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "RYD-6TPUXjOn",
        "outputId": "6d3c2d83-9da4-4ca0-c822-cd26aac85748"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_result = trainer.evaluate()\n",
        "evaluation_result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "id": "-LkWA936YosK",
        "outputId": "c922d7c1-0ad6-4493-bc98-388fe673bd00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [625/625 01:19]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 5.0,\n",
              " 'eval_f1': 0.5530755680693935,\n",
              " 'eval_loss': 1.458212971687317,\n",
              " 'eval_runtime': 79.8064,\n",
              " 'eval_samples_per_second': 62.652,\n",
              " 'eval_steps_per_second': 7.831}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_PRETRAINED_MODEL = \"/content/drive/MyDrive/NLP/hw4\"\n",
        "model.save_pretrained(PATH_TO_PRETRAINED_MODEL)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n0RzoEBZm9y",
        "outputId": "8b5f3afa-daab-4b81-9a32-1afd7ab414d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/NLP/hw4/config.json\n",
            "Model weights saved in /content/drive/MyDrive/NLP/hw4/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = ElectraForMaskedLM.from_pretrained(PATH_TO_PRETRAINED_MODEL)"
      ],
      "metadata": {
        "id": "3fljH5AgaI0s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictor_trained = pipeline(\"fill-mask\", model=trained_model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "JYwImeb50JkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predictions for 'Why don't you ask [MASK]?'\")\n",
        "print(f\"MASK can be: {[item['token_str'] for item in predictor_trained('Why don`t you ask [MASK]?')]}\")\n",
        "print(\"======================================\")\n",
        "print(\"Predictions for 'What is [MASK]'\")\n",
        "print(f\"MASK can be: {[item['token_str'] for item in predictor_trained('What is [MASK]')]}\")\n",
        "print(\"======================================\")\n",
        "print(\"Predictions for 'Let's talk about [MASK] physics'\")\n",
        "print(f\"MASK can be: {[item['token_str'] for item in predictor_trained('Let`s talk about [MASK] physics')]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cg9JwumI0ZVF",
        "outputId": "8a93b0b3-bfcd-4d00-a9e2-3d45293adef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions for 'Why don't you ask [MASK]?'\n",
            "MASK can be: ['a n k l e s', 'a i s l e s', '# # o p p e d', '# # t a n g l e d', 'c r o u c h e d']\n",
            "======================================\n",
            "Predictions for 'What is [MASK]'\n",
            "MASK can be: ['f a u l t s', '# # u r i t i e s', '# # s i b i l i t y', '# # f e l t', '# # i c i e n c i e s']\n",
            "======================================\n",
            "Predictions for 'Let's talk about [MASK] physics'\n",
            "MASK can be: ['f r a c t u r e', 'f r a c t u r e s', '# # u l a t e s', 'd o w n w a r d', '# # t u r e']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result of prediction is different because the weights of the original model change during training."
      ],
      "metadata": {
        "id": "eEW1Ilgo02ar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'\n",
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "mJM5Qdqf0fln"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "    return ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=10, return_dict=True)"
      ],
      "metadata": {
        "id": "WEcdK-Nf1HWB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    args=training_args,\n",
        "    train_dataset=training, \n",
        "    eval_dataset=test,\n",
        "    model_init=model_init,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "IYiBmyWO1OT1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4386803d-be1c-48bf-90ab-3f5dd6a3e824"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/google/electra-small-generator/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/ddf7554779ef5bd660812cf3b6c92a66e14e307bae0f8582015b43ce8f8de85c.e50e2a54975f5ef36835643600664f71c63e7f570a08222c48829a8d8e327dca\n",
            "Model config ElectraConfig {\n",
            "  \"architectures\": [\n",
            "    \"ElectraForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 128,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 256,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 1024,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 4,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.17.0\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/google/electra-small-generator/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/3198f768e07f18c7e8c6bedf8bae83eb6976a0cd29fd947f7c2eea1d03c19c74.70eb7a9661dc955e309afdd412fe4cf2a38225870027e600a01012bd47d92db4\n",
            "Some weights of the model checkpoint at google/electra-small-generator were not used when initializing ElectraForSequenceClassification: ['generator_predictions.dense.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.LayerNorm.weight', 'generator_lm_head.weight', 'generator_predictions.dense.bias', 'generator_lm_head.bias']\n",
            "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at google/electra-small-generator and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-5746624d04fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0meval_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mcompute_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplace_model_on_device\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m         \u001b[0;31m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_move_model_to_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m         \u001b[0;31m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mParallelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tie_weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    897\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    591\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    594\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    895\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    896\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 897\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB (GPU 0; 11.17 GiB total capacity; 10.55 GiB already allocated; 15.81 MiB free; 10.56 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install optuna"
      ],
      "metadata": {
        "id": "MignfThs1mVY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.hyperparameter_search(direction=\"maximize\")"
      ],
      "metadata": {
        "id": "h94hZW7z1hiC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize(psutil.virtual_memory().available), \" |     Proc size: \" + humanize.naturalsize(process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total     {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "metadata": {
        "id": "4LLS-ctd1i2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02c5475b-1d2f-4b2d-e90a-68c091bf9e27"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7411 sha256=e4bafc4a3184e81c082cab6107f1a0acac383fd1e738311c3c68a981581ed44c\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/f8/83/534c52482d6da64622ddbf72cd93c35d2ef2881b78fd08ff0c\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Gen RAM Free: 10.5 GB  |     Proc size: 5.3 GB\n",
            "GPU RAM Free: 16MB | Used: 11425MB | Util 100% | Total     11441MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "tVlk6WV8x2cB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}